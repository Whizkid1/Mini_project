{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beatifulsoup_navernews.ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 알고리즘 설계\n",
        "- URL로 부터 res 객체 생성\n",
        "- res 객체.text → 파싱\n",
        "- 파싱한 것으로 html find 해서 데이터 가져오기\n",
        "- 데이터에서 각각원하는 데이터 추출 해서 변수에 입력\n",
        "- 중복 데이터와, 헤드라인에 박근혜, 문재인 단어가 포함되어 있지 않는 경우가 있음\n",
        "- 날짜, 타이틀, 매체를 추출한 다음에 타이틀에 각각 단어가 있는 경우에만 변수에 입력하게 만듬\n"
      ],
      "metadata": {
        "id": "lf10L8v3vXOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YMVtQh4vIr7"
      },
      "outputs": [],
      "source": [
        "import requests as rs\n",
        "import pandas as pd \n",
        "from bs4 import BeautifulSoup\n",
        "import turtle as t \n",
        "\n",
        "URL = 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EB%AC%B8%EC%9E%AC%EC%9D%B8%20or%20%EB%B0%95%EA%B7%BC%ED%98%9C&sort=0&photo=0&field=0&pd=3&ds=2012.06.01&de=2012.12.17&cluster_rank=36&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from20120601to20121217,a:all&start=01'\n",
        "base_url = 'https://movie.naver.com'\n",
        "page =0\n",
        "temp_list = []\n",
        "title_store = []\n",
        "temp_page_check = 0\n",
        "while(True): #아래에 break 설치 함 \n",
        "    page += 1 \n",
        "    URL = 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EB%AC%B8%EC%9E%AC%EC%9D%B8%20or%20%EB%B0%95%EA%B7%BC%ED%98%9C&sort=0&photo=0&field=0&pd=3&ds=2012.06.01&de=2012.12.17&cluster_rank=36&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from20120601to20121217,a:all&start=0{}'.format(page)\n",
        "    res = requests.get(URL)\n",
        "    html_str = res.text\n",
        "    soup = BeautifulSoup(html_str,'html.parser')\n",
        "\n",
        "    news_list = soup.find_all(class_='news_wrap api_ani_send')\n",
        " #각 데이터 추출 \n",
        "    for row in news_list:\n",
        "        title = row.find(class_='news_tit').text\n",
        "        print(title)\n",
        "        a = 0\n",
        "        while(True): #날짜 데이터를 가져올 때 '2면 4단'이런식으로 들어오는 것을 필터링 \n",
        "            temp_date = row.find(class_=\"news_info\").find_all(class_=\"info\")[a].text\n",
        "            if '2012' in temp_date:\n",
        "                date = temp_date\n",
        "                break\n",
        "            else:\n",
        "                a += 1\n",
        "        press = row.find(class_='info press').text\n",
        "        link = row.find('a')['data-url']\n",
        "        a+=1\n",
        "        #데이터 검증 #데이터를 추출한 다음에 헤드라인에 단어 포함 되있는 경우만 변수입력\n",
        "        if title in title_store:\n",
        "            title_store.append(title)\n",
        "            pass\n",
        "        elif title not in title_store:\n",
        "            temp_list.append([title,date,press,link])\n",
        "            title_store.append(title)\n",
        "    if title_store.count(title) ==50:\n",
        "        break\n",
        "    else:\n",
        "        pass\n",
        "# 데이타프레임으로 저장 \n",
        "df_list = pd.DataFrame(temp_list, columns=['title', 'url', 'review', 'point'])\n",
        "df_movie\n",
        "\n",
        "n = 87\n",
        "t.bgcolor('black')\n",
        "t.color('yellow')\n",
        "t.speed(0)\n",
        "\n",
        "#데이터 추출 \n",
        "df_list.to_csv('election.csv', encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 피드백"
      ],
      "metadata": {
        "id": "Xsj2D8vk58rL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 자꾸 중복된 기사가 연속으로 들어오는 경우가 생김\n",
        "2. 중복된 기사가 같은 뉴스에서 긁어오는 경우가 있음\n",
        "3. 중복된 기사가 들어오면 break를 걸었지만 연속으로 들어오는 것이 고쳐지지 않음\n",
        "4. 크롤링 속도가 너무 느림\n",
        "\n"
      ],
      "metadata": {
        "id": "ovjxKg-E55Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vLWm5FjK_EEH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}